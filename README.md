# BigMartFlow
ğŸ›’ BigMart Real-Time Sales Prediction Dashboard

ğŸš€ Overview

This project showcases a real-time data pipeline and machine learning system for predicting retail sales demand using Apache Kafka, Python, and Streamlit. It simulates a dynamic retail environment where sales data is continuously streamed, processed, and visualized.

The system consists of a Kafka producer that feeds new sales records, a Kafka consumer that stores the data in a database, a trained ML model that predicts future demand, and a Streamlit dashboard that displays the top 10 latest entries with predictions in real time.

ğŸ“¦ Tech Stack

Apache Kafka â€“ for real-time data streaming

Python â€“ for scripting, data processing, and ML

scikit-learn â€“ for building the predictive model

SQLite (bigmart.db) â€“ for storing incoming data

Pandas & NumPy â€“ for data manipulation

Streamlit â€“ for creating a web-based dashboard

Docker â€“ (optional) for containerized deployment

ğŸ”„ Workflow

Kafka Producer

Reads from bigmartsales.csv line-by-line

Sends records to a Kafka topic every few seconds

Kafka Consumer

Listens to the topic

Writes the data into bigmart.db SQLite database

ML Model

A regression model (e.g., Linear Regression) is trained on historical sales data

Predicts Item_Outlet_Sales for each new record

Streamlit Dashboard

Fetches the top 10 most recent records from the database

Displays actual and predicted sales dynamically with refresh capability

ğŸ“ Project Structure

.
â”œâ”€â”€ app
â”‚   â””â”€â”€ streamlit_app.py         # Streamlit UI logic
â”œâ”€â”€ consumer.py                  # Kafka consumer script
â”œâ”€â”€ producer.py                  # Kafka producer script
â”œâ”€â”€ model.pkl                    # Trained ML model
â”œâ”€â”€ bigmart.db                   # SQLite database storing new data
â”œâ”€â”€ bigmartsalws.csv             # Sample data used by the producer
â”œâ”€â”€ requirements.txt             # Dependencies for the project
â””â”€â”€ README.md                    # Project documentation

ğŸ’» How to Run Locally

1. Start Kafka and Zookeeper

Use Docker or local Kafka setup to start Zookeeper and Kafka broker.

2. Start Producer and Consumer

python producer.py
python consumer.py

3. Launch the Dashboard

streamlit run app/streamlit_app.py

ğŸ“Š Output Preview

Top 10 latest sales records

Real-time updates every few seconds

Actual vs Predicted sales

ğŸŒ Deployment

Deployed using Streamlit Cloud. Visit the live app here: https://bigmartflow.streamlit.app

âœ¨ Highlights

Real-time data streaming & visualization

End-to-end ML integration

Lightweight and scalable design

ğŸ¤ Contributions

Feel free to fork the repo, raise issues, or submit PRs. Suggestions to improve real-time accuracy, visualization, or deployment are welcome!

ğŸ“§ Contact

Developed by Praneeth GoudğŸ“¬ Email: praneethgoud2510@gmail.com ğŸ”— GitHub: pranee123
